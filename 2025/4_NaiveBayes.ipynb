{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6ccb32e-0e4f-4660-a61a-b88a0f63c99c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Implementing the NaiveBayes Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca69b9e5-16b0-4eba-aa10-6eccd5ec6947",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "\n",
       "   Parch     Ticket     Fare Cabin Embarked  \n",
       "0      0  A/5 21171   7.2500   NaN        S  \n",
       "1      0   PC 17599  71.2833   C85        C  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df= pd.read_csv('../day5_titanic/train.csv')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d70ef3a9-adb5-4f9b-80aa-f9dfa1f2d520",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['Survived']\n",
    "X=df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Cabin', 'Embarked']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfb989ae-caa2-4128-ac4d-d2f704603ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numeric = X[['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']]\n",
    "X_categorical = X[['Sex','Embarked']]\n",
    "X_neither = X['Cabin']\n",
    "X_onehot = pd.get_dummies(X_categorical,['Sex','Embarked']).astype(int)\n",
    "X_cabin_nonna = X['Cabin'].apply(lambda x: 0 if pd.isna(x) else 1)\n",
    "X_encoded0 = pd.merge(X_numeric, X_cabin_nonna,  left_index=True, right_index=True)\n",
    "X_encoded1 = pd.merge(X_encoded0, X_onehot,  left_index=True, right_index=True)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_encoded1, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Imputer for numeric columns (e.g., Age)\n",
    "imputer = SimpleImputer(strategy='median')  # or 'mean' if you prefer\n",
    "\n",
    "# Fit on train, transform train\n",
    "X_train['Age'] = imputer.fit_transform(X_train[['Age']])\n",
    "\n",
    "# Transform test using same statistics\n",
    "X_test['Age'] = imputer.transform(X_test[['Age']])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6516565f-236c-4600-b937-27070ac7c264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.7809\n",
      "Test Accuracy:  0.7430\n"
     ]
    }
   ],
   "source": [
    "#### Application from sklearn library\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize model with default hyperparameters\n",
    "nb = GaussianNB(var_smoothing=1e-9)\n",
    "\n",
    "# Fit the model\n",
    "nb.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_train_pred = nb.predict(X_train_scaled)\n",
    "y_test_pred = nb.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate accuracy\n",
    "train_acc = accuracy_score(y_train, y_train_pred)\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Train Accuracy: {train_acc:.4f}\")\n",
    "print(f\"Test Accuracy:  {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e91c2b6-e797-491b-910e-7cf05f5941e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "skvar = nb.var_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4918f36b-ff13-42bb-848f-567c65cb64a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "skmean = nb.theta_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3affb585-b12f-4992-add5-8fb355577ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(skvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1a6fee3-b089-4fc7-af0e-7cf8ecbbcfac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 11)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skvar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8477702-9b1f-4e2a-a020-548fb02821b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07caa564-2568-4ec5-917c-1d9c31985c8b",
   "metadata": {},
   "source": [
    "### Features are not conditionally independent, need to drop one hot encoded ones and see performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ec4e4e-64da-4cf9-bd49-f66924bac2a5",
   "metadata": {},
   "source": [
    "##### Tuning hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c115aa5-76f6-443e-9e2a-11edc04b18ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best var_smoothing: 1e-09\n",
      "Best CV score: 0.7725007386979218\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'var_smoothing': np.logspace(-9, -6, 7)}\n",
    "grid = GridSearchCV(GaussianNB(), param_grid, cv=5)\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Best var_smoothing:\", grid.best_params_['var_smoothing'])\n",
    "print(\"Best CV score:\", grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2a7ea41-5494-47e7-ab19-c21cb385a1b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38342696629213485\n",
      "0.6165730337078652\n"
     ]
    }
   ],
   "source": [
    "## Implementation from Scratch\n",
    "\n",
    "p_1= (np.sum(y_train,axis=0)/np.shape(y_train)[0])\n",
    "p_1\n",
    "p_0 = 1-p_1\n",
    "print(p_1)\n",
    "print(p_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec312ad0-8fe0-4a11-a21d-385d75fa1c7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.6165730337078652)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p0 = np.mean(y_train == 0)\n",
    "p0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f719f55d-ffe0-459e-8284-2209ab7fe48d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(712,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e385a9ce-b46b-4c81-bdce-025a44b568f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mean_1 = np.mean(X_train[y_train==1],axis = 0)\n",
    "X_mean_0 = np.mean(X_train[y_train==0],axis = 0)\n",
    "\n",
    "X_std_1 = np.std(X_train[y_train==1],axis = 0, ddof=0)\n",
    "X_std_0 = np.std(X_train[y_train==0],axis = 0, ddof=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e41546a-09ab-4f79-b24c-f3bd373d8ec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c3b557b-48a3-407d-a03c-2ddc52b3722c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_mean_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a3c74793-7cb1-4d77-83ae-bac9ee078060",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance_vectors(skmean, X_mean_0, X_mean_1):\n",
    "    mean_0_np = X_mean_0#.to_numpy()\n",
    "    mean_1_np = X_mean_1#.to_numpy()\n",
    "    d0 = np.linalg.norm(skmean[0,:]-mean_0_np)\n",
    "    d1 = np.linalg.norm(skmean[1,:]-mean_1_np)\n",
    "    return (d0,d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "59a9d283-11df-4a83-8b68-3c8198664a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(np.float64(37.258430732215736), np.float64(56.08012391456066))\n"
     ]
    }
   ],
   "source": [
    "print(get_distance_vectors(skmean, X_mean_0, X_mean_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5c252a06-0572-4431-bd4d-9dd82c2561ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mean_11 = np.mean(X_train_scaled[y_train==1],axis = 0)\n",
    "X_mean_01 = np.mean(X_train_scaled[y_train==0],axis = 0)\n",
    "\n",
    "X_std_11 = np.std(X_train_scaled[y_train==1],axis = 0, ddof=0)\n",
    "X_std_01 = np.std(X_train_scaled[y_train==0],axis = 0, ddof=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "92e4d68b-1156-4ea9-a5cb-8c49094f2927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(np.float64(0.0), np.float64(0.0))\n"
     ]
    }
   ],
   "source": [
    "print(get_distance_vectors(skmean, X_mean_01, X_mean_11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ba1dd8-6050-4870-b508-2b6ccc294c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(X, mean1, std1, mean0, std0, p0):\n",
    "    '''\n",
    "    X has n_examples rows and n_features columns\n",
    "    p0 is the probability of observing class 0 in the training data\n",
    "    need to determinate if each example in X came from one multivariate gaussian or the other\n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984deb74-9aa9-4fb8-b78f-8ecb4a4788b9",
   "metadata": {},
   "source": [
    "### Gotcha!! We are doing naive bayes, naive assumption xis are condtionaly independent given yi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c10c3155-dc20-4f23-a3d4-1d7b2002c184",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mean_1 = np.mean(X_train_scaled[y_train==1],axis = 0)\n",
    "X_mean_0 = np.mean(X_train_scaled[y_train==0],axis = 0)\n",
    "\n",
    "X_std_1 = np.std(X_train_scaled[y_train==1],axis = 0, ddof=0)\n",
    "X_std_0 = np.std(X_train_scaled[y_train==0],axis = 0, ddof=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5d52e750-275c-42f5-bf9e-17b8cd7ecad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.7809\n",
      "Test Accuracy: 0.7430\n"
     ]
    }
   ],
   "source": [
    "def predict(X, mean1, std1, mean0, std0, p0):\n",
    "    \"\"\"\n",
    "    Predict class labels using Gaussian Naive Bayes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array, shape (n_samples, n_features)\n",
    "        Test data.\n",
    "    mean1, std1 : arrays of shape (n_features,)\n",
    "        Mean and std for features given class 1.\n",
    "    mean0, std0 : arrays of shape (n_features,)\n",
    "        Mean and std for features given class 0.\n",
    "    p0 : float\n",
    "        Prior probability of class 0 (P(y=0)).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    y_pred : array of shape (n_samples,)\n",
    "        Predicted class labels (0 or 1).\n",
    "    \"\"\"\n",
    "    X = np.asarray(X)         # ensure numpy array\n",
    "    mean0 = np.asarray(mean0)\n",
    "    std0 = np.asarray(std0)\n",
    "    mean1 = np.asarray(mean1)\n",
    "    std1 = np.asarray(std1)\n",
    "    eps = 1e-9  # small constant to prevent division by zero\n",
    "\n",
    "    # Compute log-likelihood for each class (vectorized)\n",
    "    log_p_x_given_0 = -0.5 * np.sum(np.log(2 * np.pi * (std0**2 + eps))) \\\n",
    "                      - 0.5 * np.sum(((X - mean0)**2) / (std0**2 + eps), axis=1)\n",
    "    \n",
    "    log_p_x_given_1 = -0.5 * np.sum(np.log(2 * np.pi * (std1**2 + eps))) \\\n",
    "                      - 0.5 * np.sum(((X - mean1)**2) / (std1**2 + eps), axis=1)\n",
    "\n",
    "    # Class priors\n",
    "    log_p0 = np.log(p0 + eps)\n",
    "    log_p1 = np.log(1 - p0 + eps)\n",
    "\n",
    "    # Posterior log-probabilities (up to constant)\n",
    "    log_posterior_0 = log_p0 + log_p_x_given_0\n",
    "    log_posterior_1 = log_p1 + log_p_x_given_1\n",
    "\n",
    "    # Predict class with higher posterior\n",
    "    y_pred = (log_posterior_1 > log_posterior_0).astype(int)\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "y_train_pred = predict(X_train_scaled, X_mean_1, X_std_1, X_mean_0, X_std_0, p_0)\n",
    "\n",
    "\n",
    "y_test_pred = predict(X_test_scaled, X_mean_1, X_std_1, X_mean_0, X_std_0, p_0)\n",
    "\n",
    "# ----------------------------\n",
    "# Evaluate accuracy\n",
    "# ----------------------------\n",
    "train_acc = accuracy_score(y_train, y_train_pred)\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Train Accuracy: {train_acc:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed5a12f-978c-4e59-93ac-cc0975474500",
   "metadata": {},
   "source": [
    "#### Plotting "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb997502-0b3a-4b1b-bcf7-f24046338d37",
   "metadata": {},
   "source": [
    "#### Gaussian naive bayes form sklearn gives accuracy of 0.74 but i get around 0.6 percent accuracy from my implementation: find what could be different and needs improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dd9195-e17a-454b-97ad-6253c3b601f0",
   "metadata": {},
   "source": [
    "###  My hunch :This should be on X_train_scaled\n",
    "\n",
    "X_mean_1 = np.mean(X_train[y_train==1],axis = 0)\n",
    "\n",
    "X_mean_0 = np.mean(X_train[y_train==0],axis = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc38d4f-ad61-468c-855f-19d29f12be6f",
   "metadata": {},
   "source": [
    "### Checking the implementation from the github repo MLfromscratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc67e6d3-25ff-4138-8e15-69410c39e1fc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class NaiveBayes:\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self._classes = np.unique(y)\n",
    "        n_classes = len(self._classes)\n",
    "\n",
    "        # calculate mean, var, and prior for each class\n",
    "        self._mean = np.zeros((n_classes, n_features), dtype=np.float64)\n",
    "        self._var = np.zeros((n_classes, n_features), dtype=np.float64)\n",
    "        self._priors = np.zeros(n_classes, dtype=np.float64)\n",
    "\n",
    "        for idx, c in enumerate(self._classes):\n",
    "            X_c = X[y == c]\n",
    "            self._mean[idx, :] = X_c.mean(axis=0)\n",
    "            self._var[idx, :] = X_c.var(axis=0)\n",
    "            self._priors[idx] = X_c.shape[0] / float(n_samples)\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = [self._predict(x) for x in X]\n",
    "        return np.array(y_pred)\n",
    "\n",
    "    def _predict(self, x):\n",
    "        posteriors = []\n",
    "\n",
    "        # calculate posterior probability for each class\n",
    "        for idx, c in enumerate(self._classes):\n",
    "            prior = np.log(self._priors[idx])\n",
    "            posterior = np.sum(np.log(self._pdf(idx, x)))\n",
    "            posterior = prior + posterior\n",
    "            posteriors.append(posterior)\n",
    "\n",
    "        # return class with highest posterior probability\n",
    "        return self._classes[np.argmax(posteriors)]\n",
    "\n",
    "    def _pdf(self, class_idx, x):\n",
    "        mean = self._mean[class_idx]\n",
    "        var = self._var[class_idx]\n",
    "        numerator = np.exp(-((x - mean) ** 2) / (2 * var))\n",
    "        denominator = np.sqrt(2 * np.pi * var)\n",
    "        return numerator / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "336f70ba-c680-4b79-9e00-dbff4d279246",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes classification accuracy 0.7430167597765364\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "def accuracy(y_true, y_pred):\n",
    "        accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
    "        return accuracy\n",
    "\n",
    "nb = NaiveBayes()\n",
    "nb.fit(X_train_scaled, y_train)\n",
    "predictions = nb.predict(X_test_scaled)\n",
    "\n",
    "'''\n",
    "y_train_pred = predict(X_train_scaled, X_mean_1, X_std_1, X_mean_0, X_std_0, p_0)\n",
    "\n",
    "\n",
    "y_test_pred = predict(X_test_scaled, X_mean_1, X_std_1, X_mean_0, X_std_0, p_0)\n",
    "\n",
    "# ----------------------------\n",
    "# Evaluate accuracy\n",
    "# ----------------------------\n",
    "train_acc = accuracy_score(y_train, y_train_pred)\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Train Accuracy: {train_acc:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "'''\n",
    "print(\"Naive Bayes classification accuracy\", accuracy(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea90e226-b5ee-49c0-85f1-c5bb91f02b29",
   "metadata": {},
   "source": [
    "## Fixed the error\n",
    "### Compute the priors on the scaled data, that was what the predict method was seeing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680bef99-437e-4c24-b3cb-0452f66a8d6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
