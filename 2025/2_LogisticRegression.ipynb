{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee2daa4b-0ca1-4ede-9d1e-b21ba1df2a77",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Implementation of the Logistic Regression Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "415f9f69-40df-48ee-894d-d8c52d4e48b9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df= pd.read_csv('../day5_titanic/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88ee575d-f69a-46dd-a4ee-32ad8c7825ae",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "\n",
       "   Parch     Ticket     Fare Cabin Embarked  \n",
       "0      0  A/5 21171   7.2500   NaN        S  \n",
       "1      0   PC 17599  71.2833   C85        C  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a85a26d-5ac9-462c-9a8b-ac1b071798bc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y=df['Survived']\n",
    "X=df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Cabin', 'Embarked']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a14d4bc-f14e-4310-9076-564e89e4ffde",
   "metadata": {},
   "source": [
    "### Question: Standardize first bring numerical features on 0-1 scale or convert categorical to 0,1  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff831f1-a92d-4a23-8326-a7452120f3be",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### Question Follow up: What does standard scaler do?\n",
    "\n",
    "You’re absolutely right:\n",
    "👉 You should apply StandardScaler only to your original numeric features,\n",
    "👉 and not to one-hot encoded categorical columns (from pd.get_dummies).\n",
    "\n",
    "\n",
    "✅ Why we don’t scale one-hot encoded columns\n",
    "\n",
    "One-hot columns are already 0s and 1s.\n",
    "Scaling them would destroy their meaning — you’d end up with non-binary values that no longer represent categories.\n",
    "The goal of scaling is to make numeric features comparable, not to modify encoded categories.\n",
    "Standard scaler is (X-mu)/(std_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d2e74a8-c28a-4612-9ee2-95f5a2c302ed",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_numeric = X[['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']]\n",
    "X_categorical = X[['Sex','Embarked']]\n",
    "X_neither = X['Cabin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ba758b6e-3100-432c-960d-1e3f6b165ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass      0\n",
       "Age       177\n",
       "SibSp       0\n",
       "Parch       0\n",
       "Fare        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_numeric.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae5477c2-f60e-48a2-a0a5-6ac0a478d130",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_onehot = pd.get_dummies(X_categorical,['Sex','Embarked']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e41cce3b-0ec1-480a-a3b9-d535f4dc24f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S\n",
       "0           0         1           0           0           1\n",
       "1           1         0           1           0           0\n",
       "2           1         0           0           0           1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_onehot.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9c9bf24-4913-4a6c-b6ff-dc405cfe6325",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_cabin_nonna = X['Cabin'].apply(lambda x: 0 if pd.isna(x) else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b11fb68c-e913-4162-a279-46e2296fecc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    0\n",
       "3    1\n",
       "4    0\n",
       "Name: Cabin, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cabin_nonna.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc848e9a-0d7c-491e-8340-6ab39fc1f33a",
   "metadata": {},
   "source": [
    "### Do train test split before applying standard scaler to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62247253-3028-4e0c-8a34-3cc60aaa2bf9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_encoded0 = pd.merge(X_numeric, X_cabin_nonna,  left_index=True, right_index=True)\n",
    "X_encoded1 = pd.merge(X_encoded0, X_onehot,  left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0b0a31b2-9e75-4cd4-ac1d-b46508b5c76b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_encoded1, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f949dd41-cedb-44dd-a886-b08e89674308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e17a1ac7-780f-4074-95f2-059524954b0f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Imputer for numeric columns (e.g., Age)\n",
    "imputer = SimpleImputer(strategy='median')  # or 'mean' if you prefer\n",
    "\n",
    "# Fit on train, transform train\n",
    "X_train['Age'] = imputer.fit_transform(X_train[['Age']])\n",
    "\n",
    "# Transform test using same statistics\n",
    "X_test['Age'] = imputer.transform(X_test[['Age']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6ea74aca-264d-4ddd-a63d-1c645a33161d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "943176f2-d851-4a8f-bc02-8633d4f9d457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.82956755, -0.6573438 , -0.46508428, -0.46618317, -0.48696219,\n",
       "       -0.5383819 , -0.74242727,  0.74242727, -0.49252705, -0.28933346,\n",
       "        0.61631563])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled[5,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d713d4-e1d8-4cd9-8a97-11278e4988df",
   "metadata": {},
   "source": [
    "### Logisitc Regression from Sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e1f313b6-65ae-468f-8711-1a769e3e5668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Logistic Regression Results\n",
      "--------------------------------\n",
      "Accuracy: 0.8156\n",
      "\n",
      "Confusion Matrix:\n",
      "[[97 13]\n",
      " [20 49]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.85       110\n",
      "           1       0.79      0.71      0.75        69\n",
      "\n",
      "    accuracy                           0.82       179\n",
      "   macro avg       0.81      0.80      0.80       179\n",
      "weighted avg       0.81      0.82      0.81       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assuming you already have:\n",
    "# X_train_scaled, X_test_scaled, y_train, y_test\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# 1️⃣ Create and train the model\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 2️⃣ Make predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# 3️⃣ Evaluate performance\n",
    "print(\"✅ Logistic Regression Results\")\n",
    "print(\"--------------------------------\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc7f15a-89b2-441b-80e8-e2e73abe9db9",
   "metadata": {},
   "source": [
    "### Implementation of algorithm from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61468b6-11d7-4ddb-a727-1e31169201c9",
   "metadata": {},
   "source": [
    "#### Given X_train, t_train, X_test, y_test\n",
    "#### Hyperparameter alpha- the learning rate, threshold -delta beyond which we can stop training\n",
    "Derive the cost function analytically, solve the local optima which is also the global optima\n",
    "Compute gradient of cost function\n",
    "\n",
    "## Cost function: -yi log yi_hat - (1 - yi) log( 1- yi_hat)\n",
    "The yis are not identical the ones outside the log function are ground truth\n",
    "The ones inside are 1/(1 + e^ (-theta T X))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91cc5b3-3098-4b37-ae2c-4ed315027033",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "![Alt text](./logistic.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9b755d43-a3f8-4def-82b4-d93d7a01e007",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, cost=0.699835\n",
      "Iteration 1000, cost=0.437621\n",
      "Iteration 2000, cost=0.432054\n",
      "Iteration 3000, cost=0.431007\n",
      "Iteration 4000, cost=0.430683\n",
      "Converged at iteration 4765, cost=0.430575\n",
      "Test accuracy: 0.8045\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ----------------------------\n",
    "# Helper functions\n",
    "# ----------------------------\n",
    "\n",
    "def sigmoid(z):\n",
    "    \"\"\"Sigmoid activation function.\"\"\"\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def compute_cost(y_true, y_pred):\n",
    "    \"\"\"Binary cross-entropy / log loss.\"\"\"\n",
    "    m = len(y_true)\n",
    "    # To avoid log(0), clip predictions\n",
    "    y_pred = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
    "    cost = - (1/m) * np.sum(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "    return cost\n",
    "\n",
    "def predict_probs(X, w, b):\n",
    "    \"\"\"Compute predicted probabilities.\"\"\"\n",
    "    return sigmoid(np.dot(X, w) + b)\n",
    "\n",
    "def predict_classes(X, w, b, threshold=0.5):\n",
    "    \"\"\"Predict class labels (0 or 1) given threshold.\"\"\"\n",
    "    probs = predict_probs(X, w, b)\n",
    "    return (probs >= threshold).astype(int)\n",
    "\n",
    "# ----------------------------\n",
    "# Logistic Regression from scratch\n",
    "# ----------------------------\n",
    "\n",
    "def logistic_regression_train(X_train, y_train, alpha=0.01, threshold=1e-6, max_iter=20000):\n",
    "    \"\"\"\n",
    "    Train logistic regression using gradient descent.\n",
    "    \n",
    "    Parameters:\n",
    "    X_train: np.array, shape (m, n)\n",
    "    y_train: np.array, shape (m,)\n",
    "    alpha: learning rate\n",
    "    threshold: minimum change in cost for stopping\n",
    "    max_iter: maximum iterations\n",
    "    \n",
    "    Returns:\n",
    "    w, b : trained weights and bias\n",
    "    \"\"\"\n",
    "    m, n = X_train.shape\n",
    "    # Initialize weights and bias\n",
    "    w = np.random.randn(n) * 0.01\n",
    "    b = 0.0\n",
    "    \n",
    "    prev_cost = float('inf')\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        # 1️⃣ Forward pass\n",
    "        y_pred = predict_probs(X_train, w, b)\n",
    "        \n",
    "        # 2️⃣ Compute gradients\n",
    "        dw = (1/m) * np.dot(X_train.T, (y_pred - y_train))\n",
    "        db = (1/m) * np.sum(y_pred - y_train)\n",
    "        \n",
    "        # 3️⃣ Update weights and bias\n",
    "        w -= alpha * dw\n",
    "        b -= alpha * db\n",
    "        \n",
    "        # 4️⃣ Compute cost and check stopping criterion\n",
    "        cost = compute_cost(y_train, y_pred)\n",
    "        if abs(prev_cost - cost) < threshold:\n",
    "            print(f\"Converged at iteration {i}, cost={cost:.6f}\")\n",
    "            break\n",
    "        prev_cost = cost\n",
    "        \n",
    "        # Optional: print every 1000 iterations\n",
    "        if i % 1000 == 0:\n",
    "            print(f\"Iteration {i}, cost={cost:.6f}\")\n",
    "    \n",
    "    return w, b\n",
    "\n",
    "# ----------------------------\n",
    "# Train the model\n",
    "# ----------------------------\n",
    "w, b = logistic_regression_train(X_train_scaled, y_train, alpha=0.01, threshold=1e-7)\n",
    "\n",
    "# ----------------------------\n",
    "# Predict on test data\n",
    "# ----------------------------\n",
    "y_pred_test = predict_classes(X_test_scaled, w, b)\n",
    "\n",
    "\n",
    "# Optional: Evaluate accuracy\n",
    "accuracy = np.mean(y_pred_test == y_test)\n",
    "print(f\"Test accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22cd68e-a4f0-4485-90fe-2925058074d4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (microsoft_prep_venv)",
   "language": "python",
   "name": "microsoft_prep_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
